# Early Alzheimerâ€™s Disease Detection from Structural MRIs Using Deep Learning

## ğŸ§  Overview

![GIF via GradCam](media/CN+MCI+AD.gif)

This project explores the use of **3D Convolutional Neural Networks (3D CNNs)** for early detection of Alzheimerâ€™s Disease (AD) using structural magnetic resonance imaging (sMRI). Inspired by and building upon the work of [Liu et al. (2022)](https://www.nature.com/articles/s41598-022-20674-x), we aim to not only replicate but **enhance their deep learning architecture** using high-performance computing (HPC) resources, particularly the **MeluXina Supercomputer**.

The model classifies subjects into three categories:  
- **Cognitively Normal (CN)**  
- **Mild Cognitive Impairment (MCI)**  
- **Mild AD Dementia (AD)**  

Our work highlights the value of deep learning in automating and improving the diagnostic process for Alzheimerâ€™s Disease, enabling scalable and efficient MRI-based screening.

---

## âœ… Contributions

- Re-implemented and validated Liu et al.â€™s 3D CNN model on the ADNI dataset   
- Used the **Clinica software suite** for standardized MRI preprocessing in BIDS format 
- Integrated  **data augmentation** techniques (Gaussian blurring, random cropping)  
- Leveraged **MeluXina HPC** for full-scale GPU-based training and evaluation  
- Achieved promising classification results with improved performance on the original paper

---

## ğŸ—ï¸ Model Architecture

![Model Architecture Placeholder](media/pipeline_inst_batch.png)

> *Note: Figure shows a placeholder representation of the deep learning architecture.*

The model architecture consists of:
- Multiple 3D convolutional blocks with normalization steps and ReLU activations  
- Fully connected layers for classification  
- Cross-entropy loss optimized with Adam  

---

## ğŸ“¦ Data Pipeline

### Dataset: [ADNI](http://adni.loni.usc.edu/)

| session_id | participant_id | sex | original_study | diagnosis | ... |
|------------|----------------|-----|----------------|-----------|-----|
| ses-M006   | sub-ADNI052S0671 | F   | ADNI1          | LMCI      | ... |
| ses-M000   | sub-ADNI109S0967 | M   | ADNI1          | CN        | ... |
| ses-M000   | sub-ADNI027S0850 | M   | ADNI1          | AD        | ... |

## âš™ï¸ Preprocessing

To collect the MRI scans and utilize them correctly to train the model please refer to [INSTALL.md](INSTALL.md)

MRI scans were processed using the [Clinica software suite](https://www.clinica.run/):

1. Convert to **BIDS format**
2. Generate a **template** from the training set
3. Apply **spatial normalization** using the template
4. Apply **intensity normalization** to reduce scanner bias

This pipeline ensures data consistency across training, validation, and testing sets.

---

## ğŸ” Data Augmentation

To improve generalization and model robustness, we applied:

- **Gaussian Blurring** 
- **Random Cropping**  

Augmentation is performed **on-the-fly** during training.

---

## ğŸ’» Infrastructure: MeluXina Supercomputer

We worked on the GPU-enabled **MeluXina** system provided by EuroHPC.

### SSH Access

```bash
# ~/.ssh/config
Host meluxina
  Hostname login.lxp.lu
  User <user_id>
  Port 8822
  IdentityFile ~/.ssh/id_ed25519_mel
  IdentitiesOnly yes
  ForwardAgent no
```
To connect simply type on the command line
```bash
ssh meluxina
```

## ğŸš€ Benefits of MeluXina

* Large amount of GPU hours available

* Support for large batch sizes

* GPU parallelization capabilities

* Extended memory for ~1TB datasets  

---

## ğŸ§ª Neural Network Training

- **Loss Function**: Cross-Entropy  
- **Optimizer**: Adam
- **Normalization**: InstanceNorm / BatchNorm   

Most of the model parameters can be tuned by modifying the [config.yaml](config.yaml) file.

---

## ğŸ“ˆ Results

> **NOTE:** Placeholder section. Insert metrics when available.

Expected outcomes based on Liu et al.:

- **AUC > 89.21%** for AD classification  
- Improved performance over ROI-volume/thickness-based models  
- Demonstrated progression prediction capabilities  

---

## ğŸ–¼ï¸ Visualizations

We implemented **Grad-CAM** to interpret model decisions and highlight the most discriminative brain regions contributing to each prediction (**CN / MCI / AD**). The visualization pipeline generates **GIF overlays for axial, coronal, and sagittal slices**, color-coded by predicted diagnosis:

- ğŸŸ© **Green** = CN  
- ğŸŸ¨ **Yellow** = MCI  
- ğŸŸ¥ **Red** = AD  

Additionally, an **optional hippocampal crop** (based on the AAL atlas) is used to focus on clinically relevant areas, automatically handled via `nilearn`.

To define which part of the Grad-CAM heatmap is considered "active", the script supports multiple **thresholding strategies**, selectable via `--threshold_mode`:

- `pct`: retains the top-N% activations (configurable via `--pct`, e.g., `--pct 60` for 60%)
- `otsu`: uses Otsuâ€™s adaptive method
- `std`: keeps voxels with activation > mean + *k* Ã— std (`--std_k 0.5`, etc.)

This interpretability module offers visual insight into model behavior, improves clinical trust, and highlights class-specific decision regions.

---

## ğŸ“‚ Project Structure
```bash
â”œâ”€â”€ python/                  # Python Model
â”‚   â”œâ”€â”€ model.py               # CNN architecture
â”‚   â”œâ”€â”€ dataset.py             # Dataset preparation
â”‚   â”œâ”€â”€ test.py                # Test perfomance script
â”‚   â”œâ”€â”€ test.sh                # Shell script for test.py
â”‚   â”œâ”€â”€ train.py               # Main training script 
â”‚   â””â”€â”€ train.sh               # Shell script for train.py
â”œâ”€â”€ cpp/                     # C++ Model
â”‚   â”œâ”€â”€ CMakeLists.txt         # CMake config file
â”‚   â”œâ”€â”€ model.h                # CNN architecture
â”‚   â”œâ”€â”€ dataset.h              # Dataset preparation
â”‚   â”œâ”€â”€ config.h               # Parameters config
â”‚   â”œâ”€â”€ test.cpp               # Test perfomance script
â”‚   â”œâ”€â”€ test.sh                # Shell script for test.cpp
â”‚   â”œâ”€â”€ train.cpp              # Main training script
â”‚   â””â”€â”€ train.sh               # Shell script for train.cpp
â”œâ”€â”€ utils/                   # Other code
â”‚   â”œâ”€â”€ plot_metrics.py        # Plot loss, Plot accuracy
â”‚   â”œâ”€â”€ plot_metrics.sh        # Shell script for plot_metrics.py
â”‚   â””â”€â”€ spm_get_doc.m          # MATLAB script for Nipype troubleshooting
â”œâ”€â”€ preprocess/              # Preprocessing scripts
â”‚   â”œâ”€â”€ run_convert.sh         # ADNI -> BIDS convertion
â”‚   â”œâ”€â”€ run_adni_preproc.sh    # T1-volume segmentation on training set
â”‚   â””â”€â”€ run_adni_valtest.sh    # T1-volume segmentation on val & test set
â”œâ”€â”€ data/                    # Diagnosis datasets
â”‚   â”œâ”€â”€ participants_Test.tsv  # Subjects in the test set
â”‚   â”œâ”€â”€ participants_Train.tsv # Subjects in the train set
â”‚   â””â”€â”€ participants_Val.tsv   # Subjects in the validation set
â”œâ”€â”€ envs/                    # Conda Environments
â”‚   â”œâ”€â”€ clinicaEnv.yml         # Conda Env for Clinica
â”‚   â”œâ”€â”€ gradcamEnv.yml         # Conda Env for Grad-CAM
â”‚   â””â”€â”€ trainEnv.yml           # Conda Env for Training
â”œâ”€â”€ gradcam/                 # Grad-CAM visualization
â”‚   â”œâ”€â”€ gradcam_out/           # Folder containing Grad-CAM outputs
â”‚   â”œâ”€â”€ visualize.py           # Script for Grad-CAM visualization
â”‚   â”œâ”€â”€ gradcam_otsu.sh        # Shell script for visualize.py w/Otsu
â”‚   â”œâ”€â”€ gradcam_std.sh         # Shell script for visualize.py w/std
â”‚   â””â”€â”€ gradcam_pct.sh         # Shell script for visualize.py w/pct
â”œâ”€â”€ results/                 # Output files containing Test results
â”‚   â”œâ”€â”€ cpp/                   # Folder containing C++ results
â”‚   â”œâ”€â”€ python/                # Folder containing Python results
â”‚   â””â”€â”€ Test_Results.ipynb     # Notebook for model evaluation metrics
â”œâ”€â”€ media/                   # Images/GIFs/...
â”œâ”€â”€ config.yaml              # Model hyperparameters
â”œâ”€â”€ INSTALL.md
â”œâ”€â”€ README.md
â””â”€â”€ report.pdf
```

## ğŸ™ Acknowledgements
- **Liu et al.** for their foundational model and research

- **MeluXina Support Team** for infrastructure and consultation

- **Clinica Developers** for powerful neuroimaging tools

- **MOX Lab @ Politecnico di Milano** for support and guidance

## ğŸ“¬ Contacts
```bash
â”œâ”€â”€ Vittorio Pio Remigio Cozzoli, Student, Politecnico di Milano
â”‚     â”œâ”€â”€ vittoriopio.cozzoli@mail.polimi.it
â”œâ”€â”€ Tommaso Crippa, Student, Politecnico di Milano
â”‚     â”œâ”€â”€ tommaso2.crippa@mail.polimi.it
â”œâ”€â”€ Alberto Taddei, Student, Politecnico di Milano
â”‚     â”œâ”€â”€ alberto4.taddei@mail.polimi.it
```

## License and Ethical Use Notice

All rights reserved.  
This repository contains research code developed for academic purposes only.  
Images and medical data used in this project are derived from publicly available datasets (ADNI), that are not linked to any identifiable individuals.  

Nevertheless, as the subject matter involves sensitive neuroimaging data, we kindly ask users to treat visual outputs with scientific respect.  
Any clinical, diagnostic, or commercial usage of this code or its outputs is strictly prohibited without prior written permission.

If you are a researcher or instructor and wish to reuse this material for non-commercial academic use, please contact the authors.
